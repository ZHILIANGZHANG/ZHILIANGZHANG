<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cheng Zhang (Rylan) - Academic Homepage</title>
    <style>
        :root {
            --text-color: #212529; 
            --secondary-text-color: #6c757d; 
            --accent-color: #005ea2; 
            --background-color: #f8f9fa; 
            --divider-color: #e9ecef;
            --tag-background-color: #e9ecef; /* 背景色用于标签 */
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            line-height: 1.7;
            color: var(--text-color);
            background-color: var(--background-color);
            max-width: 720px;
            margin: 3rem auto;
            padding: 2rem;
        }

        header {
            text-align: center;
            margin-bottom: 4rem;
        }

        /* 新增：个人照片样式 */
        .profile-photo {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            margin: 0 auto 1.5rem;
            object-fit: cover;
            display: block;
        }

        h1, h2 {
            line-height: 1.3;
            color: #111;
        }

        h1 {
            font-size: 2.5rem;
            font-weight: 700;
            letter-spacing: -0.5px;
            margin-bottom: 0.25rem;
        }

        header p {
            margin: 0.5rem 0;
            font-size: 1.1rem;
            color: var(--secondary-text-color);
        }

        .contact-links a {
            margin: 0 0.6em;
            font-weight: 500;
            color: var(--secondary-text-color);
            transition: color 0.2s ease;
        }
        .contact-links a:hover {
            color: var(--accent-color);
            text-decoration: none;
        }

        h2 {
            font-size: 1.5rem;
            font-weight: 600;
            margin-top: 3rem;
            margin-bottom: 1.5rem;
            padding-left: 0.8rem;
            border-left: 3px solid var(--accent-color);
        }

        p {
            margin-bottom: 1em;
        }
        
        a {
            color: var(--accent-color);
            text-decoration: none;
            font-weight: 500;
        }

        a:hover {
            text-decoration: underline;
        }

        ul {
            list-style: none;
            padding-left: 0;
        }

        ul li:not(:last-child) {
            border-bottom: 1px solid var(--divider-color);
            padding-bottom: 1.5rem;
            margin-bottom: 1.5rem;
        }
        
        ul li {
            padding-left: 0.2rem;
        }
        
        .publication-title, .item-title {
            font-weight: 600;
            font-size: 1.05rem;
            color: #343a40;
        }
        
        .item-header {
            display: flex;
            justify-content: space-between;
            align-items: baseline;
            flex-wrap: wrap;
            gap: 0.5rem;
        }
        
        .item-meta {
            color: var(--secondary-text-color);
            font-size: 0.9rem;
            flex-shrink: 0;
        }

        .authors, .subtitle {
            font-size: 0.95rem;
            color: var(--secondary-text-color);
            margin-top: 0.3em;
        }
        
        .authors strong {
            color: var(--text-color);
            font-weight: 500;
        }

        .venue {
            font-style: italic;
        }
        .venue em {
             color: var(--secondary-text-color);
             font-size: 0.9rem;
             margin-left: 0.5rem;
        }
        
        /* 新增：教育背景标签样式 */
        .edu-tag {
            display: inline-block;
            background-color: var(--tag-background-color);
            color: var(--secondary-text-color);
            font-size: 0.7rem;
            font-weight: 500;
            text-transform: uppercase;
            padding: 0.2rem 0.6rem;
            border-radius: 12px;
            margin-left: 0.5rem;
            vertical-align: middle;
        }

    </style>
</head>
<body>

    <header>
        <!-- 照片已添加至此处 -->
        <img src="selfish.png" alt="Cheng Zhang Profile Photo" class="profile-photo">
        
        <h1>Cheng Zhang (Rylan)</h1>
        <p>Undergraduate Researcher, Jilin University</p>
        <p class="contact-links">
            <a href="mailto:zhangcheng2122@mails.jlu.edu.cn">Email</a> ·
            <a href="#">Google Scholar</a> ·
            <a href="#">GitHub</a> ·
            <a href="#">LinkedIn</a>
        </p>
    </header>

    <main>
        <section id="about">
            <h2>About Me</h2>
            <p>I am an undergraduate researcher at Jilin University, passionate about advancing artificial intelligence. My research centers on the intersection of Multi-Modal Large Language Models, Computer Vision, and Affective Computing.</p>
            <p>I am driven by the challenge of building systems that can holistically perceive, reason, and interact with the world. My work involves creating models that seamlessly integrate diverse data modalities, exploring how machines can achieve a deeper understanding of visual information, and ultimately bridging the gap between computational and emotional intelligence.</p>
        </section>

        <section id="publications">
            <h2>Publications</h2>
            <ul>
                <li>
                    <p class="publication-title">EmoArt: A Multidimensional Dataset for Emotion-Aware Artistic Generation</p>
                    <p class="authors"><strong>Cheng Zhang</strong>, HongXia Xie, Bin Wen, Songhan Zuo, Ruoxuan Zhang, Wen-Huang Cheng</p>
                    <p class="venue">ACM Multimedia (Dataset Track) 2025 <em>(Under Review)</em></p>
                </li>
                <li>
                    <p class="publication-title">EmoDiscover: Vocabulary-free Emotion Discovery via Multi-modal Large Language Model</p>
                    <p class="authors">Hung-Jen Chen, Hongxia Xie, <strong>Cheng Zhang</strong>, Songhan Zuo, Chu-Jun Peng, Hong-Han Shuai, Yong Man Ro, Wen-Huang Cheng</p>
                    <p class="venue">International Conference on Computer Vision (ICCV) 2025 <em>(Under Review)</em></p>
                </li>
                <li>
                    <p class="publication-title">Single Document Image Highlight Removal via A Large-Scale Real-World Dataset and A Location-Aware Network</p>
                    <p class="authors">Lu Pan, Yu-Hsuan Huang, Hongxia Xie, <strong>Cheng Zhang</strong>, Hongwei Zhao, Hong-Han Shuai, Wen-Huang Cheng</p>
                    <p class="venue">ACM Multimedia (ACM MM) 2025 <em>(Under Review)</em></p>
                </li>
                <li>
                    <p class="publication-title">AmorisBench: A Comprehensive Multi-modal Dataset for Love-centric Question Answering</p>
                    <p class="authors">Chu-Jun Peng, Hongxia Xie, <strong>Cheng Zhang</strong>, Wen-Huang Cheng</p>
                    <p class="venue">ACM Multimedia (Dataset Track) 2025 <em>(Under Review)</em></p>
                </li>
            </ul>
        </section>

        <section id="experience">
            <h2>Research Experience</h2>
            <ul>
                <li>
                    <div class="item-header">
                        <p class="item-title">Affective Vision Computing (AVC) Lab, Jilin University</p>
                        <p class="item-meta">2024 – Present</p>
                    </div>
                    <p class="subtitle">Role: Research Assistant | Supervisor: A/Prof. Hongxia Xie</p>
                    <p>Contributing to projects in affective computing and multi-modal machine learning. Developing novel methods to understand and model emotional responses from visual and textual data.</p>
                </li>
                <li>
                    <div class="item-header">
                        <p class="item-title">National & Provincial Research Projects</p>
                        <p class="item-meta">Jan 2025 – Present</p>
                    </div>
                    <p class="subtitle">Role: Participant</p>
                    <p>Participating in two key projects: (1) A National Natural Science Foundation Youth Project on eliminating emotion hallucination in V-L models, and (2) A Jilin Provincial Excellent Youth Project on enhancing emotion understanding stability in multimodal large models.</p>
                </li>
            </ul>
        </section>

        <section id="education">
            <h2>Education</h2>
            <ul>
                <li>
                    <div class="item-header">
                        <!-- 标签已添加至此处 -->
                        <p class="item-title">
                            Jilin University
                            <span class="edu-tag">985 & 211</span>
                            <span class="edu-tag">Double First-Class (A)</span>
                        </p>
                        <p class="item-meta">2022 – 2026 (Expected)</p>
                    </div>
                    <p class="subtitle">B.Sc. in Computer Science & Technology</p>
                    <p>GPA: 3.54/4.0 | Rank: 7/102</p>
                </li>
            </ul>
        </section>
        
        <section id="honors">
            <h2>Honors & Awards</h2>
            <ul>
                <li>
                    <div class="item-header">
                        <p class="item-title">Undergraduate Scholarship, Jilin University</p>
                        <p class="item-meta">2023 – 2024</p>
                    </div>
                </li>
                 <li>
                    <div class="item-header">
                        <p class="item-title">Undergraduate Scholarship, Jilin University</p>
                        <p class="item-meta">2022 – 2023</p>
                    </div>
                </li>
            </ul>
        </section>
        
    </main>

</body>
</html>
